
  # pre-trained model
  https://github.com/AIRC-KETI/ke-t5 
KE-T5: Korean-English T5
KE-T5는 Text-to-Text Transfer Transformer 모델을 한국어와 영어 코퍼스를 이용하여 사전학습한 모델입니다.

Vocabulary는 64,000개의 sub-word token으로 이루어져 있으며, Google의 sentencepiece를 이용하여 만들었습니다. Sentencepiece 모델은 한국어와 영어가 약 7:3의 비율로 섞인 30GB의 코퍼스를 99.95% 커버하도록 학습되었습니다.

사전학습에 사용된 비정형 코퍼스에 대한 구성과 정보는 Datasets을 참고하시기 바랍니다.

